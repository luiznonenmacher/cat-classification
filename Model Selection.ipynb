{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the bottleneck features to train a model to predict the cats. For each of the three transfer learning models, we will try some alternatives to find the best one in terms of accuracy.\n",
    "\n",
    "For every model the structure will be the same: we will import the bottleneck features as X, the labels as y and divide X and y into training, validation and test sets. After, we will train some models and select the best one in terms of validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NasNet Large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4032)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('data/bottleneck_features/nasnet_bottleneck.npy')\n",
    "y = np.load('data/processed_data/y.npy')\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, \n",
    "                                                  random_state=42, shuffle=True, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model will be the most simple one, as we will just add a final layer with one neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 1)                 4033      \n",
      "=================================================================\n",
      "Total params: 4,033\n",
      "Trainable params: 4,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(1, activation='relu', input_shape=(4032,)))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.9412\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "epochs = 100\n",
    "checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.nasnet_1.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "model1.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_predictions_1 = (model1.predict(X_train) > 0.5) * 1\n",
    "val_predictions_1 = (model1.predict(X_val) > 0.5) * 1\n",
    "train_accuracy_1 = accuracy_score(train_predictions_1, y_train)\n",
    "val_accuracy_1 = accuracy_score(val_predictions_1, y_val)\n",
    "\n",
    "print('Training accuracy: {}'.format(np.round(train_accuracy_1,4)))\n",
    "print('Validation accuracy: {}'.format(np.round(val_accuracy_1,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model is more complex than the first model because we added a 10-neuron fully connected layer before the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 10)                40330     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 40,341\n",
      "Trainable params: 40,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(10, activation='relu', input_shape=(4032,)))\n",
    "model2.add(Dense(1, activation='relu'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.902\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "epochs = 300\n",
    "checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.nasnet_2.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "model2.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "train_predictions_2 = (model2.predict(X_train) > 0.5) * 1\n",
    "val_predictions_2 = (model2.predict(X_val) > 0.5) * 1\n",
    "train_accuracy_2 = accuracy_score(train_predictions_2, y_train)\n",
    "val_accuracy_2 = accuracy_score(val_predictions_2, y_val)\n",
    "\n",
    "print('Training accuracy: {}'.format(np.round(train_accuracy_2,3)))\n",
    "print('Validation accuracy: {}'.format(np.round(val_accuracy_2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 10)                40330     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 40,341\n",
      "Trainable params: 40,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(10, activation='relu', input_shape=(4032,)))\n",
    "model3.add(Dropout(rate=0.2))\n",
    "model3.add(Dense(1, activation='relu'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.922\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "set_random_seed(42)\n",
    "\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "epochs = 300\n",
    "checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.nasnet_3.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "model3.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "train_predictions_3 = (model3.predict(X_train) > 0.5) * 1\n",
    "val_predictions_3 = (model3.predict(X_val) > 0.5) * 1\n",
    "train_accuracy_3 = accuracy_score(train_predictions_3, y_train)\n",
    "val_accuracy_3 = accuracy_score(val_predictions_3, y_val)\n",
    "\n",
    "print('Training accuracy: {}'.format(np.round(train_accuracy_3,3)))\n",
    "print('Validation accuracy: {}'.format(np.round(val_accuracy_3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1000)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('data/bottleneck_features/xception_bottleneck.npy')\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, \n",
    "                                                  random_state=42, shuffle=True, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 100,201\n",
      "Trainable params: 100,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(100, activation='relu', input_shape=(1000,)))\n",
    "model1.add(Dropout(rate=0.2))\n",
    "model1.add(Dense(1, activation='relu', input_shape=(1000,)))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "epochs = 300\n",
    "checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.xception_1.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "model1.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=0)\n",
    "\n",
    "\n",
    "train_predictions_1 = (model1.predict(X_train) > 0.5) * 1\n",
    "val_predictions_1 = (model1.predict(X_val) > 0.5) * 1\n",
    "train_accuracy_1 = accuracy_score(train_predictions_1, y_train)\n",
    "val_accuracy_1 = accuracy_score(val_predictions_1, y_val)\n",
    "\n",
    "print('Training accuracy: {}'.format(np.round(train_accuracy_1,4)))\n",
    "print('Validation accuracy: {}'.format(np.round(val_accuracy_1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
