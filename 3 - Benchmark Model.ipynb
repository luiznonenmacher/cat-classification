{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we train a CNN without using transfer learning, to serve as a benchmark for the models using transfer learning in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training, validation and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the train, validation and test set. All the sets are shuffled but balanced in terms of classes (y always contains 50% of each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('data/processed_data/X_299.npy')\n",
    "y = np.load('data/processed_data/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, \n",
    "                                                  random_state=42, shuffle=True, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set contains 289 examples, the validation contains 51 and the test set 60\n"
     ]
    }
   ],
   "source": [
    "print('The training set contains {} examples, the validation contains {} and the test set {}'\n",
    "      .format(X_train.shape[0], X_val.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the benchmark models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train three models as benchmarks to the next step of the project. For the three models, the best weight (evaluatead by validation loss) will be saved in the benchmark_models folder.\n",
    "\n",
    "I will compare the three models by their validation accuracy and then obtain the test accuracy for the best model. This test accuracy will be the benchmark accuracy that we want our final model to get improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model is the most simple one, it contains two pairs of convolution/max pooling layers, a GAP layer and finally a 1-neuron dense layer that predict the probability of the picture being 1 (Kuki). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 299, 299, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 149, 149, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,321\n",
      "Trainable params: 2,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(299,299,3)))\n",
    "model1.add(MaxPooling2D(pool_size=2))\n",
    "model1.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=2))\n",
    "model1.add(GlobalAveragePooling2D())\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 289 samples, validate on 51 samples\n",
      "Epoch 1/20\n",
      "289/289 [==============================] - 12s 42ms/step - loss: 0.7773 - acc: 0.5156 - val_loss: 0.7176 - val_acc: 0.4510\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71765, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 2/20\n",
      "289/289 [==============================] - 12s 43ms/step - loss: 0.7008 - acc: 0.5190 - val_loss: 0.6907 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71765 to 0.69069, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 3/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.6980 - acc: 0.5744 - val_loss: 0.6914 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69069\n",
      "Epoch 4/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.6941 - acc: 0.5606 - val_loss: 0.6899 - val_acc: 0.5098\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69069 to 0.68993, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 5/20\n",
      "289/289 [==============================] - 13s 45ms/step - loss: 0.6919 - acc: 0.5986 - val_loss: 0.6867 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.68993 to 0.68670, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 6/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.6889 - acc: 0.5848 - val_loss: 0.6857 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68670 to 0.68566, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 7/20\n",
      "289/289 [==============================] - 13s 46ms/step - loss: 0.6879 - acc: 0.5709 - val_loss: 0.6838 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68566 to 0.68384, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 8/20\n",
      "289/289 [==============================] - 14s 47ms/step - loss: 0.6858 - acc: 0.5709 - val_loss: 0.6837 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.68384 to 0.68373, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 9/20\n",
      "289/289 [==============================] - 13s 45ms/step - loss: 0.6868 - acc: 0.5398 - val_loss: 0.6805 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.68373 to 0.68053, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 10/20\n",
      "289/289 [==============================] - 13s 46ms/step - loss: 0.6905 - acc: 0.5917 - val_loss: 0.6795 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.68053 to 0.67949, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 11/20\n",
      "289/289 [==============================] - 12s 43ms/step - loss: 0.6786 - acc: 0.5709 - val_loss: 0.6757 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.67949 to 0.67574, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 12/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.6764 - acc: 0.6367 - val_loss: 0.6739 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.67574 to 0.67388, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 13/20\n",
      "289/289 [==============================] - 14s 47ms/step - loss: 0.6725 - acc: 0.5709 - val_loss: 0.6733 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.67388 to 0.67327, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 14/20\n",
      "289/289 [==============================] - 14s 48ms/step - loss: 0.6701 - acc: 0.6159 - val_loss: 0.6734 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.67327\n",
      "Epoch 15/20\n",
      "289/289 [==============================] - 13s 46ms/step - loss: 0.6727 - acc: 0.5606 - val_loss: 0.6747 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.67327\n",
      "Epoch 16/20\n",
      "289/289 [==============================] - 14s 48ms/step - loss: 0.6682 - acc: 0.6055 - val_loss: 0.6688 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.67327 to 0.66879, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 17/20\n",
      "289/289 [==============================] - 14s 47ms/step - loss: 0.6665 - acc: 0.5571 - val_loss: 0.6698 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.66879\n",
      "Epoch 18/20\n",
      "289/289 [==============================] - 14s 47ms/step - loss: 0.6776 - acc: 0.5433 - val_loss: 0.6665 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.66879 to 0.66650, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n",
      "Epoch 19/20\n",
      "289/289 [==============================] - 13s 45ms/step - loss: 0.6698 - acc: 0.6125 - val_loss: 0.6674 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.66650\n",
      "Epoch 20/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.6652 - acc: 0.5986 - val_loss: 0.6644 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.66650 to 0.66437, saving model to benchmark_models/weights.best.benchmark_1.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2130f8cd940>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='models/benchmark_models/weights.best.benchmark_1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model1.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first model, the validation accuracy was 0.667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions_1 = (model1.predict(X_val) > 0.5) * 1\n",
    "val_accuracy_1 = accuracy_score(predictions_1, y_val)\n",
    "\n",
    "print('For the first model, the validation accuracy was {}'.format(np.round(val_accuracy_1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model is a bit more complex; I added one more fully-connected layer with 16 neurons followed by a dropout of 0.2 before the final fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 299, 299, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 149, 149, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,833\n",
      "Trainable params: 2,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(299,299,3)))\n",
    "model2.add(MaxPooling2D(pool_size=2))\n",
    "model2.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2))\n",
    "model2.add(GlobalAveragePooling2D())\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(1, activation='relu'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 289 samples, validate on 51 samples\n",
      "Epoch 1/20\n",
      "289/289 [==============================] - 12s 42ms/step - loss: 4.0469 - acc: 0.4913 - val_loss: 0.8098 - val_acc: 0.5098\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80983, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 2/20\n",
      "289/289 [==============================] - 12s 41ms/step - loss: 0.9168 - acc: 0.5156 - val_loss: 0.6933 - val_acc: 0.4902\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80983 to 0.69328, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 3/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.8503 - acc: 0.5190 - val_loss: 0.6893 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69328 to 0.68931, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 4/20\n",
      "289/289 [==============================] - 12s 43ms/step - loss: 0.7631 - acc: 0.4740 - val_loss: 0.6928 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.68931\n",
      "Epoch 5/20\n",
      "289/289 [==============================] - 12s 43ms/step - loss: 0.7444 - acc: 0.4983 - val_loss: 0.6911 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.68931\n",
      "Epoch 6/20\n",
      "289/289 [==============================] - 13s 43ms/step - loss: 0.7348 - acc: 0.4879 - val_loss: 0.6927 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.68931\n",
      "Epoch 7/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.7302 - acc: 0.5329 - val_loss: 0.6874 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68931 to 0.68744, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 8/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.7464 - acc: 0.4844 - val_loss: 0.6888 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.68744\n",
      "Epoch 9/20\n",
      "289/289 [==============================] - 13s 45ms/step - loss: 0.7157 - acc: 0.5433 - val_loss: 0.6847 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.68744 to 0.68474, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 10/20\n",
      "289/289 [==============================] - 13s 45ms/step - loss: 0.7179 - acc: 0.5260 - val_loss: 0.6833 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.68474 to 0.68331, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 11/20\n",
      "289/289 [==============================] - 13s 45ms/step - loss: 0.7189 - acc: 0.5329 - val_loss: 0.6839 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.68331\n",
      "Epoch 12/20\n",
      "289/289 [==============================] - 13s 45ms/step - loss: 0.7350 - acc: 0.5017 - val_loss: 0.6815 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.68331 to 0.68146, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 13/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.7208 - acc: 0.5467 - val_loss: 0.6794 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68146 to 0.67941, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 14/20\n",
      "289/289 [==============================] - 12s 43ms/step - loss: 0.7382 - acc: 0.5260 - val_loss: 0.6791 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.67941 to 0.67915, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 15/20\n",
      "289/289 [==============================] - 13s 44ms/step - loss: 0.7436 - acc: 0.4983 - val_loss: 0.6819 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.67915\n",
      "Epoch 16/20\n",
      "289/289 [==============================] - 14s 47ms/step - loss: 0.6956 - acc: 0.5536 - val_loss: 0.6783 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.67915 to 0.67833, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 17/20\n",
      "289/289 [==============================] - 15s 52ms/step - loss: 0.7028 - acc: 0.5640 - val_loss: 0.6755 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.67833 to 0.67555, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 18/20\n",
      "289/289 [==============================] - 14s 48ms/step - loss: 0.7065 - acc: 0.5536 - val_loss: 0.6744 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.67555 to 0.67443, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n",
      "Epoch 19/20\n",
      "289/289 [==============================] - 12s 40ms/step - loss: 0.7237 - acc: 0.5433 - val_loss: 0.6787 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.67443\n",
      "Epoch 20/20\n",
      "289/289 [==============================] - 12s 43ms/step - loss: 0.7146 - acc: 0.5156 - val_loss: 0.6721 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.67443 to 0.67205, saving model to benchmark_models/weights.best.benchmark_2.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x213097bc978>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='models/benchmark_models/weights.best.benchmark_2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model2.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the second model, the validation accuracy was 0.647\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = (model2.predict(X_val) > 0.5) * 1\n",
    "val_accuracy_2 = accuracy_score(predictions_2, y_val)\n",
    "\n",
    "print('For the second model, the validation accuracy was {}'.format(np.round(val_accuracy_2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third model is similar to the second model, but I added one more convolutional / max pooling layer pair before the GAP layer. Also, I increased the size of the fully connected layer to 20 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 299, 299, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 149, 149, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 74, 74, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 11,865\n",
      "Trainable params: 11,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(299,299,3)))\n",
    "model3.add(MaxPooling2D(pool_size=2))\n",
    "model3.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=2))\n",
    "model3.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=2))\n",
    "model3.add(GlobalAveragePooling2D())\n",
    "model3.add(Dense(20, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(1, activation='relu'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 289 samples, validate on 51 samples\n",
      "Epoch 1/20\n",
      "289/289 [==============================] - 16s 54ms/step - loss: 0.8687 - acc: 0.5190 - val_loss: 0.6975 - val_acc: 0.5098\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69755, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 2/20\n",
      "289/289 [==============================] - 15s 52ms/step - loss: 0.7237 - acc: 0.5225 - val_loss: 0.7024 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69755\n",
      "Epoch 3/20\n",
      "289/289 [==============================] - 15s 53ms/step - loss: 0.7282 - acc: 0.5121 - val_loss: 0.6942 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69755 to 0.69423, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 4/20\n",
      "289/289 [==============================] - 15s 53ms/step - loss: 0.7106 - acc: 0.5329 - val_loss: 0.6970 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.69423\n",
      "Epoch 5/20\n",
      "289/289 [==============================] - 15s 52ms/step - loss: 0.7044 - acc: 0.5709 - val_loss: 0.6929 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.69423 to 0.69290, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 6/20\n",
      "289/289 [==============================] - 16s 56ms/step - loss: 0.7509 - acc: 0.5052 - val_loss: 0.6938 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.69290\n",
      "Epoch 7/20\n",
      "289/289 [==============================] - 16s 54ms/step - loss: 0.7128 - acc: 0.5087 - val_loss: 0.6919 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.69290 to 0.69191, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 8/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.7158 - acc: 0.5329 - val_loss: 0.6904 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.69191 to 0.69044, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 9/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.7379 - acc: 0.5329 - val_loss: 0.6917 - val_acc: 0.5294\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69044\n",
      "Epoch 10/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.7436 - acc: 0.5087 - val_loss: 0.6834 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.69044 to 0.68335, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 11/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.7257 - acc: 0.5606 - val_loss: 0.6968 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.68335\n",
      "Epoch 12/20\n",
      "289/289 [==============================] - 14s 50ms/step - loss: 0.7191 - acc: 0.5433 - val_loss: 0.6803 - val_acc: 0.5490\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.68335 to 0.68032, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 13/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.7492 - acc: 0.5882 - val_loss: 0.6710 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68032 to 0.67099, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 14/20\n",
      "289/289 [==============================] - 14s 50ms/step - loss: 0.7092 - acc: 0.5536 - val_loss: 0.6723 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.67099\n",
      "Epoch 15/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.6659 - acc: 0.6194 - val_loss: 0.6659 - val_acc: 0.6863\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.67099 to 0.66590, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 16/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.6803 - acc: 0.5813 - val_loss: 0.6634 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.66590 to 0.66344, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 17/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.7162 - acc: 0.5709 - val_loss: 0.6717 - val_acc: 0.7059\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.66344\n",
      "Epoch 18/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.6766 - acc: 0.6021 - val_loss: 0.6496 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.66344 to 0.64957, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n",
      "Epoch 19/20\n",
      "289/289 [==============================] - 14s 49ms/step - loss: 0.6368 - acc: 0.6263 - val_loss: 0.6768 - val_acc: 0.7255\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.64957\n",
      "Epoch 20/20\n",
      "289/289 [==============================] - 14s 50ms/step - loss: 0.6596 - acc: 0.6678 - val_loss: 0.6472 - val_acc: 0.5882\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.64957 to 0.64717, saving model to benchmark_models/weights.best.benchmark_3.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21309f649e8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='models/benchmark_models/weights.best.benchmark_3.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model3.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the third model, the validation accuracy was 0.588\n"
     ]
    }
   ],
   "source": [
    "predictions_3 = (model3.predict(X_val) > 0.5) * 1\n",
    "val_accuracy_3 = accuracy_score(predictions_3, y_val)\n",
    "\n",
    "print('For the third model, the validation accuracy was {}'.format(np.round(val_accuracy_3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three trained models obtained the following validation accuracy:\n",
    "\n",
    "__First model:__ 0.666 <br>\n",
    "__Second model:__ 0.647 <br>\n",
    "__Third model:__ 0.588 <br>\n",
    "\n",
    "Those results comproved my intuition that simpler models would have a better performance, given the small dataset that we have. Now, we calculate the test accuracy for the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is 0.617\n"
     ]
    }
   ],
   "source": [
    "predictions = (model1.predict(X_test) > 0.5) * 1\n",
    "test_accuracy = accuracy_score(predictions, y_test)\n",
    "\n",
    "print('The test accuracy is {}'.format(np.round(test_accuracy, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy that will be used as benchmark is 0.617"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
