{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the bottleneck features to train a model to predict the cats. For each of the three transfer learning models, we will try some alternatives to find the best one in terms of validation accuracy.\n",
    "\n",
    "For every model we will test three alternatives: the first one with just a 1-neuron layer to predict the final class, the second one adding a 10-neuron fully connected layer before the last layer and the third alternative adding a dropout layer (rate of 0.2) after the 10-neuron layer.\n",
    "\n",
    "To train every model and find it's validation performance we will run 5 times and collect the average accuracy. In each of the runs, we will generate a new train and validation set, use the training set to train the model and evaluate the accuracy in the validation set. \n",
    "\n",
    "After all models were run, we select the best one to be the reference and find its test set accuracy, to compare with the benchmark model obtained on the prior notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.backend import clear_session\n",
    "from tensorflow import set_random_seed\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NasNet Large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4032)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('data/bottleneck_features/nasnet_bottleneck.npy')\n",
    "y = np.load('data/processed_data/y.npy')\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.9216\n",
      "Model 2, accuracy: 0.9608\n",
      "Model 3, accuracy: 0.9412\n",
      "Model 4, accuracy: 0.9608\n",
      "Model 5, accuracy: 0.9804\n",
      "The model mean validation accuracy was: 0.9529\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='relu', input_shape=(4032,)))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.nasnet_1.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4)))\n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.5294\n",
      "Model 2, accuracy: 0.9412\n",
      "Model 3, accuracy: 0.9216\n",
      "Model 4, accuracy: 0.9216\n",
      "Model 5, accuracy: 0.9804\n",
      "The model mean validation accuracy was: 0.8588\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(4032,)))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.nasnet_2.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4)))\n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.902\n",
      "Model 2, accuracy: 0.9608\n",
      "Model 3, accuracy: 0.9216\n",
      "Model 4, accuracy: 0.9804\n",
      "Model 5, accuracy: 0.9804\n",
      "The model mean validation accuracy was: 0.949\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(4032,)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.nasnet_3.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4))) \n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('data/bottleneck_features/xception_bottleneck.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.5098\n",
      "Model 2, accuracy: 0.5098\n",
      "Model 3, accuracy: 0.5098\n",
      "Model 4, accuracy: 0.4902\n",
      "Model 5, accuracy: 0.4902\n",
      "The model mean validation accuracy was: 0.502\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='relu', input_shape=(1000,)))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.xception_1.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4)))\n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.7255\n",
      "Model 2, accuracy: 0.8824\n",
      "Model 3, accuracy: 0.8235\n",
      "Model 4, accuracy: 0.4902\n",
      "Model 5, accuracy: 0.7647\n",
      "The model mean validation accuracy was: 0.7373\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(1000,)))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.xception_2.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4)))\n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.8039\n",
      "Model 2, accuracy: 0.5098\n",
      "Model 3, accuracy: 0.8627\n",
      "Model 4, accuracy: 0.4902\n",
      "Model 5, accuracy: 0.4902\n",
      "The model mean validation accuracy was: 0.6314\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(1000,)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.xception_3.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4)))\n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1536)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('data/bottleneck_features/inception_bottleneck.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.9216\n",
      "Model 2, accuracy: 0.8824\n",
      "Model 3, accuracy: 0.9412\n",
      "Model 4, accuracy: 0.9608\n",
      "Model 5, accuracy: 0.4902\n",
      "The model mean validation accuracy was: 0.8392\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='relu', input_shape=(1536,)))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.inception_1.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4)))\n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.5098\n",
      "Model 2, accuracy: 0.9804\n",
      "Model 3, accuracy: 0.9804\n",
      "Model 4, accuracy: 0.4902\n",
      "Model 5, accuracy: 0.9804\n",
      "The model mean validation accuracy was: 0.7882\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(1536,)))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.inception_2.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4)))\n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, accuracy: 0.9216\n",
      "Model 2, accuracy: 0.9804\n",
      "Model 3, accuracy: 0.9804\n",
      "Model 4, accuracy: 0.4902\n",
      "Model 5, accuracy: 0.5098\n",
      "The model mean validation accuracy was: 0.7765\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "epochs = 50\n",
    "\n",
    "for i in range(5):\n",
    "    # Split the data into train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, \n",
    "                                                  random_state=i + 42, shuffle=True, stratify=y_train_val)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(1536,)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    # Set the random seeds\n",
    "    seed(i + 42)\n",
    "    set_random_seed(i + 42)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/transfer_learning/weights.best.inception_2.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, \n",
    "               batch_size=32, callbacks=[checkpointer], verbose=0)\n",
    "    \n",
    "    # Calculate the validation accuracy\n",
    "    val_predictions = (model.predict(X_val) > 0.5) * 1\n",
    "    val_accuracy = accuracy_score(val_predictions, y_val)\n",
    "    accuracy.append(val_accuracy)\n",
    "    print('Model {}, accuracy: {}'.format(i+1, np.round(val_accuracy, 4)))\n",
    "    \n",
    "print('The model mean validation accuracy was: {}'.format(np.round(np.mean(accuracy),4)))  \n",
    "\n",
    "# Clear the model for the further models\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compare the results for the three transfer learning models (Nasnet, Xception and Inception) for each of thre three models tested. We also added a column to compare the input size for each model (size of the bottleneck features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M1 Accuracy</th>\n",
       "      <th>M2 Accuracy</th>\n",
       "      <th>M3 Accuracy</th>\n",
       "      <th>Input size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nasnet</th>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xception</th>\n",
       "      <td>0.5020</td>\n",
       "      <td>0.7373</td>\n",
       "      <td>0.6314</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inception</th>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.7765</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           M1 Accuracy  M2 Accuracy  M3 Accuracy  Input size\n",
       "Nasnet          0.9529       0.8588       0.9400        4032\n",
       "Xception        0.5020       0.7373       0.6314        1000\n",
       "Inception       0.8392       0.7882       0.7765        1536"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'M1 Accuracy': [0.9529, 0.5020, 0.8392], \n",
    "     'M2 Accuracy': [0.8588, 0.7373, 0.7882], \n",
    "     'M3 Accuracy': [0.9400, 0.6314, 0.7765],\n",
    "     'Input size': [4032, 1000, 1536]}\n",
    "results = pd.DataFrame(data=d, index=['Nasnet', 'Xception', 'Inception'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this comparison, it is easy to see that the Nasnet had the best total performance in the three model alternatives tested. The main reason that I found for this is the input size of the model (4 times the Xception and 2.5 times the Inception), which is a important characteristic given that we have a small dataset, so the more information we could get from each sample the better.\n",
    "\n",
    "Comparing the three models for Nasnet we found that the best one if the first alternative, the simplest model just containing the output layer. This model had the best accuracy probably because it avoided overfitting (given it's small size) and this shows how good the pre-trained weights in the Nasnet was for this particular problem. Given this, we now will use this first model to calculate the test set accuracy, to compare with the benchmark model trained previously (0.617)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9167\n"
     ]
    }
   ],
   "source": [
    "X = np.load('data/bottleneck_features/nasnet_bottleneck.npy')\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='relu', input_shape=(4032,)))\n",
    "model.load_weights('models/transfer_learning/weights.best.nasnet_1.hdf5')\n",
    "\n",
    "test_predictions = (model.predict(X_test) > 0.5) * 1\n",
    "test_accuracy = accuracy_score(test_predictions, y_test)\n",
    "print(np.round(test_accuracy,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final test accuracy was 0.9167, a great improvement from the 0.617 of the benchmark model and a great result overall considering the small dataset that we have available (just 400 images). This shows the power of transfer learning to solve new problems with small datasets.\n",
    "\n",
    "We also can see that the test accuracy was lower than the validation accuracy (from 0.9529 to 0.9167). This is an indication of overfitting, which is expected given the small size of the data. In the next notebook we will try to mitigate this problem by using image augmentation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
